{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd==1.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd==1.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from urduhack.preprocessing import *\n",
    "from urduhack.tokenization import *\n",
    "from urduhack.normalization import *\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the train data from all the csv files in the dataset folder and merging into a single dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"urdu-news-dataset-1M.csv\", usecols = ['Headline', \"Category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>عالمی بینک عسکریت پسندی سے متاثرہ خاندانوں کی ...</td>\n",
       "      <td>Business &amp; Economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>مالی سال 2020 ریٹرن فائل کرنے والوں کی تعداد م...</td>\n",
       "      <td>Business &amp; Economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>جاپان کو سندھ کے خصوصی اقتصادی زون میں سرمایہ ...</td>\n",
       "      <td>Business &amp; Economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>برامدات 767 فیصد بڑھ کر ارب 16 کروڑ ڈالر سے زائد</td>\n",
       "      <td>Business &amp; Economics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>کے الیکٹرک کو اضافی بجلی گیس کی فراہمی کے قانو...</td>\n",
       "      <td>Business &amp; Economics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Headline              Category\n",
       "0  عالمی بینک عسکریت پسندی سے متاثرہ خاندانوں کی ...  Business & Economics\n",
       "1  مالی سال 2020 ریٹرن فائل کرنے والوں کی تعداد م...  Business & Economics\n",
       "2  جاپان کو سندھ کے خصوصی اقتصادی زون میں سرمایہ ...  Business & Economics\n",
       "3   برامدات 767 فیصد بڑھ کر ارب 16 کروڑ ڈالر سے زائد  Business & Economics\n",
       "4  کے الیکٹرک کو اضافی بجلی گیس کی فراہمی کے قانو...  Business & Economics"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sports                                   454335\n",
       "Entertainment                            253730\n",
       "Business & Economics                     251169\n",
       "Science & Technology                      79105\n",
       "https://www.dawnnews.tv/news/1134162/         1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[(train_data[\"Category\"] == \"Sports\") | (train_data[\"Category\"] == \"Entertainment\") | (train_data[\"Category\"] == \"Business & Economics\") | (train_data[\"Category\"] == \"Science & Technology\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sports                  454335\n",
       "Entertainment           253730\n",
       "Business & Economics    251169\n",
       "Science & Technology     79105\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data[\"Headline\"]\n",
    "y = train_data[\"Category\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(830671,)\n",
      "(207668,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding the labels of the dataset into a numric form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and applying the cleaning function to clean the text of the while dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = [\"اب\",\"ابھی\",\"اپنا\",\"اپنے\",\"اپنی\",\"اٹھا\",\"اس\",\"اسے\",\"اسی\",\"اگر\",\"ان\",\"انہوں\",\"انہی\",\"انہیں\",\"انھیں\",\"او\",\"اور\",\"اے\",\"ایسا\",\"ایسے\",\"ایسی\",\"ایک\",\"آ\",\"آتا\",\"آتے\",\"آتی\",\"آگے\",\"آنا\",\"آنے\",\"آنی\",\"آئے\",\"آئی\",\"آئیں\",\"آیا\",\"با\",\"بڑا\",\"بڑے\",\"بڑی\",\"بعد\",\"بعض\",\"بلکہ\",\"بہت\",\"بھی\",\"بے\",\"پاس\",\"پر\",\"پہلے\",\"پھر\",\"تا\",\"تاکہ\",\"تب\",\"تجھ\",\"تجھے\",\"تک\",\"تم\",\"تمام\",\"تمہارا\",\"تمہارے\",\"تمھارے\",\"تمہاری\",\"تمہیں\",\"تمھیں\",\"تھا\",\"تھے\",\"تھی\",\"تھیں\",\"تو\",\"تیری\",\"تیرے\",\"جا\",\"جاتا\",\"جاتی\",\"جاتے\",\"جاتی\",\"جانے\",\"جانی\",\"جاؤ\",\"جائے\",\"جائیں\",\"جب\",\"جس\",\"جن\",\"جنہوں\",\"جنہیں\",\"جو\",\"جیسا\",\"جیسے\",\"جیسی\",\"جیسوں\",\"چاہیئے\",\"چلا\",\"چاہے\",\"چونکہ\",\"حالاں\",\"حالانکہ\",\"دو\",\"دونوں\",\"دوں\",\"دے\",\"دی\",\"دیا\",\"دیں\",\"دیے\",\"دیتا\",\"دیتے\",\"دیتی\",\"دینا\",\"دینے\",\"دینی\",\"دیئے\",\"ڈالا\",\"ڈالنا\",\"ڈالنے\",\"ڈالنی\",\"ڈالے\",\"ڈالی\",\"ذرا\",\"رکھا\",\"رکھتا\",\"رکھتے\",\"رکھتی\",\"رکھنا\",\"رکھنے\",\"رکھنی\",\"رکھے\",\"رکھی\",\"رہ\",\"رہا\",\"رہتا\",\"رہتے\",\"رہتی\",\"رہنا\",\"رہنے\",\"رہنی\",\"رہو\",\"رہے\",\"رہی\",\"رہیں\",\"زیادہ\",\"سا\",\"سامنے\",\"سب\",\"سکتا\",\"سو\",\"سے\",\"سی\",\"شاید\",\"صرف\",\"طرح\",\"طرف\",\"عین\",\"کا\",\"کبھی\",\"کچھ\",\"کہہ\",\"کر\",\"کرتا\",\"کرتے\",\"کرتی\",\"کرنا\",\"کرنے\",\"کرو\",\"کروں\",\"کرے\",\"کریں\",\"کس\",\"کسے\",\"کسی\",\"کہ\",\"کہا\",\"کہے\",\"کو\",\"کون\",\"کوئی\",\"کے\",\"کی\",\"کیا\",\"کیسے\",\"کیوں\",\"کیونکہ\",\"کیے\",\"کئے\",\"گا\",\"گویا\",\"گے\",\"گی\",\"گیا\",\"گئے\",\"گئی\",\"لا\",\"لاتا\",\"لاتے\",\"ل\",\"اتی\",\"لانا\",\"لانے\",\"لانی\",\"لایا\",\"لائے\",\"لائی\",\"لگا\",\"لگے\",\"لگی\",\"لگیں\",\"لو\",\"لے\",\"لی\",\"لیا\",\"لیتا\",\"لیتے\",\"لیتی\",\"لیکن\",\"لیں\",\"لیے\",\"لئے\",\"مجھ\",\"مجھے\",\"مگر\",\"میرا\",\"میرے\",\"میری\",\"میں\",\"نا\",\"نہ\",\"نہایت\",\"نہیں\",\"نے\",\"ہاں\",\"ہر\",\"ہم\",\"ہمارا\",\"ہمارے\",\"ہماری\",\"ہو\",\"ہوا\",\"ہوتا\",\"ہوتے\",\"ہوتی\",\"ہوتیں\",\"ہوں\",\"ہونا\",\"ہونگے\",\"ہونے\",\"ہونی\",\"ہوئے\",\"ہوئی\",\"ہوئیں\",\"ہے\",\"ہی\",\"ہیں\",\"و\",\"والا\",\"والوں\",\"والے\",\"والی\",\"وہ\",\"وہاں\",\"وہی\",\"وہیں\",\"یا\",\"یعنی\",\"یہ\",\"یہاں\",\"یہی\",\"یہیں\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = normalize_whitespace(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_accents(text)\n",
    "    text = replace_urls(text)\n",
    "    text = replace_emails(text)\n",
    "    text = replace_currency_symbols(text)\n",
    "    text = normalize_characters(text)\n",
    "    text = normalize_combine_characters(text)\n",
    "    text = english_characters_space(text)\n",
    "    text = digits_space(text)\n",
    "    text = text.lower()\n",
    "    text = normalize(text)\n",
    "    words = text.split()\n",
    "    words = [word for word in words if not word in stopwords_list]\n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_map = map(clean_text, list(X_train.values))\n",
    "X_test_map = map(clean_text, list(X_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = list(X_train_map)\n",
    "X_test = list(X_test_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "import pickle\n",
    "\n",
    "filename = 'Vectorizer_News.sav'\n",
    "pickle.dump(vectorizer, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the random forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8481"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 1 0 3 3 0 3 0 3 3 1 3 3 0 3 0 0 0 1 0 1 1 3 1 3 1 1 3 0]\n",
      "[3 2 1 0 3 3 2 0 0 3 3 1 3 2 0 3 3 0 0 1 0 0 1 3 2 3 1 1 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[:30])\n",
    "print(y_test[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'RF_Model.sav'\n",
    "pickle.dump(rfc, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the SVC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8844"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'SVC_Model.sav'\n",
    "pickle.dump(svc, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the SGDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8954\n",
      "[3 0 1 0 3 3 0 0 0 3]\n",
      "[3 2 1 0 3 3 2 0 0 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, y_train)\n",
    "SGDClassifier()\n",
    "y_pred = sgd.predict(X_test)\n",
    "print(\"Accuracy\",accuracy_score(y_test,y_pred))\n",
    "\n",
    "print(y_pred[:10])\n",
    "print(y_test[:10])\n",
    "\n",
    "import pickle\n",
    "\n",
    "filename = 'SGD_Model.sav'\n",
    "pickle.dump(sgd, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8015"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dtc.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'Decision_tree_Model.sav'\n",
    "pickle.dump(dtc, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the best model over a single text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test over a single text file\n",
    "text = \"آسان کام ہوگا\"\n",
    "text = clean_text(text)\n",
    "text = vectorizer.transform([text])\n",
    "label = sgd.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Business & Economics', 'Entertainment', 'Science & Technology',\n",
       "       'Sports'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
